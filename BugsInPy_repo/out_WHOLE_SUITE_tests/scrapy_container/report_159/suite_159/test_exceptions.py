# Test cases automatically generated by Pynguin (https://www.pynguin.eu).
# Please check them before you use them.
import pytest
import exceptions as module_0
import builtins as module_1


@pytest.mark.xfail(strict=True)
def test_case_0():
    close_spider_0 = module_0.CloseSpider()
    assert close_spider_0.reason == "cancelled"
    close_spider_1 = module_0.CloseSpider()
    assert close_spider_1.reason == "cancelled"
    module_0.IgnoreRequest(*close_spider_1)


@pytest.mark.xfail(strict=True)
def test_case_1():
    tuple_0 = ()
    not_supported_0 = module_0.NotSupported()
    module_0.IgnoreRequest(**tuple_0)


@pytest.mark.xfail(strict=True)
def test_case_2():
    dont_close_spider_0 = module_0.DontCloseSpider()
    close_spider_0 = module_0.CloseSpider()
    assert close_spider_0.reason == "cancelled"
    list_0 = [close_spider_0]
    not_supported_0 = module_0.NotSupported(*list_0)
    str_0 = "C@_"
    str_1 = "\n    Perform any argument value coercion necessary for SSL client parameters.\n\n    Valid keyword arguments to this function are all L{IReactorSSL.connectSSL}\n    arguments except for C{contextFactory}.  Instead, C{certKey} (the path name\n    of the certificate file) C{privateKey} (the path name of the private key\n    associated with the certificate) are accepted and used to construct a\n    context factory.\n\n    Valid positional arguments to this function are host and port.\n\n    @param caCertsDir: The one parameter which is not part of\n        L{IReactorSSL.connectSSL}'s signature, this is a path name used to\n        construct a list of certificate authority certificates.  The directory\n        will be scanned for files ending in C{.pem}, all of which will be\n        considered valid certificate authorities for this connection.\n\n    @type caCertsDir: C{str}\n\n    @return: The coerced values as a C{dict}.\n    "
    dict_0 = {str_0: not_supported_0, str_0: str_1}
    module_0.ContractFail(*list_0, **dict_0)


def test_case_3():
    scrapy_deprecation_warning_0 = module_0.ScrapyDeprecationWarning()
    list_0 = [
        scrapy_deprecation_warning_0,
        scrapy_deprecation_warning_0,
        scrapy_deprecation_warning_0,
    ]
    not_configured_0 = module_0.NotConfigured(*list_0)
    none_type_0 = None
    close_spider_0 = module_0.CloseSpider()
    assert close_spider_0.reason == "cancelled"
    close_spider_1 = module_0.CloseSpider(none_type_0)
    assert close_spider_1.reason is None
    not_configured_1 = module_0.NotConfigured()
    close_spider_2 = module_0.CloseSpider()
    assert close_spider_2.reason == "cancelled"
    list_1 = []
    drop_item_0 = module_0.DropItem(*list_1)
    list_2 = [close_spider_2, close_spider_1, none_type_0]
    scrapy_deprecation_warning_1 = module_0.ScrapyDeprecationWarning(*list_2)


@pytest.mark.xfail(strict=True)
def test_case_4():
    close_spider_0 = module_0.CloseSpider()
    assert close_spider_0.reason == "cancelled"
    close_spider_1 = module_0.CloseSpider()
    assert close_spider_1.reason == "cancelled"
    module_0.IgnoreRequest(**close_spider_1)


def test_case_5():
    contract_fail_0 = module_0.ContractFail()
    contract_fail_1 = module_0.ContractFail()
    not_supported_0 = module_0.NotSupported()
    none_type_0 = None
    usage_error_0 = module_0.UsageError()
    assert usage_error_0.print_help is True
    scrapy_deprecation_warning_0 = module_0.ScrapyDeprecationWarning()
    list_0 = [contract_fail_1, contract_fail_1]
    not_configured_0 = module_0.NotConfigured(*list_0)
    list_1 = [none_type_0, none_type_0]
    dont_close_spider_0 = module_0.DontCloseSpider(*list_1)
    dict_0 = {}
    dont_close_spider_1 = module_0.DontCloseSpider(**dict_0)
    not_supported_1 = module_0.NotSupported()
    close_spider_0 = module_0.CloseSpider()
    assert close_spider_0.reason == "cancelled"
    dont_close_spider_2 = module_0.DontCloseSpider()
    usage_error_1 = module_0.UsageError()
    assert usage_error_1.print_help is True
    none_type_1 = None
    list_2 = [none_type_1, none_type_1, none_type_1, none_type_1]
    scrapy_deprecation_warning_1 = module_0.ScrapyDeprecationWarning(*list_2, **dict_0)
    list_3 = [dict_0, scrapy_deprecation_warning_1, close_spider_0]
    drop_item_0 = module_0.DropItem(*list_3)
    close_spider_1 = module_0.CloseSpider()
    assert close_spider_1.reason == "cancelled"
    contract_fail_2 = module_0.ContractFail(**dict_0)


@pytest.mark.xfail(strict=True)
def test_case_6():
    scrapy_deprecation_warning_0 = module_0.ScrapyDeprecationWarning()
    bool_0 = True
    not_configured_0 = module_0.NotConfigured()
    list_0 = [bool_0, not_configured_0, bool_0, bool_0]
    not_supported_0 = module_0.NotSupported(*list_0)
    str_0 = "ENGINE STATUS ------------------------------------------------------- \r\n"
    dict_0 = {str_0: bool_0}
    module_0.DropItem(**dict_0)


@pytest.mark.xfail(strict=True)
def test_case_7():
    assertion_error_0 = module_1.AssertionError()
    int_0 = 1049
    tuple_0 = (assertion_error_0, int_0, assertion_error_0)
    module_0.UsageError(*assertion_error_0, **tuple_0)
